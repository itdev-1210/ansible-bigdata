# ========================
# role-wide parameters
# ========================

# The name of HDFS cluster
# You should use the cluster name or NameNode's URL
#
cdh5_spark_hdfs_cluster_name: 'mycluster'

# ====================================
# Each configuration file parameters
# ====================================

# spark-defaults.conf
cdh5_spark_master: 'yarn'
cdh5_spark_logdir: 'hdfs://{{ cdh5_spark_hdfs_cluster_name }}/var/log/spark'
cdh5_spark_historyserver: '{{ groups["hadoop_other"][0] }}'
cdh5_spark_historyserver: '{{ groups["hadoop_other"][0] }}'

# spark-env.sh
cdh5_spark_exe_instances: '1'
cdh5_spark_exe_cores: '1'
cdh5_spark_exe_mem: '400M'
cdh5_spark_dri_mem: '400M'
cdh5_spark_history_dir: 'hdfs://{{ cdh5_spark_hdfs_cluster_name }}/var/log/spark'

# /etc/default/spark
cdh5_spark_scala_home: '/usr/local/scala/default'
#
# /etc/spark/conf/metrics.properties
cdh5_spark_graphite_enabled: True
cdh5_spark_graphite_prefix: 'spark'
cdh5_spark_graphite_port: '2003'
